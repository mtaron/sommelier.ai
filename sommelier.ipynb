{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sommelier.ai\n",
    "#### Practical Machine Learning Workshop\n",
    "\n",
    "### Agenda:\n",
    "- Data Exploration with pandas\n",
    "- Modeling with scikit-learn\n",
    "\n",
    "### Tools and Documentation\n",
    "- [pandas](https://pandas.pydata.org/pandas-docs/stable/api.html)\n",
    "- [scikit-learn](http://scikit-learn.org/stable/index.html)\n",
    "- [matplotlib](https://matplotlib.org/api/api_overview.html)\n",
    "\n",
    "\n",
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These 'magics' alter the behavior of the Jupyter notebook\n",
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from workshop import boxplot_sorted\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/winemag-data.zip\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loc example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.province == \"Washington\") & (df.points > 98)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[45]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How are wines scored?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.points.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.points.plot.hist(title=\"Points\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Challenges\n",
    "- what are the worst wines in the US?\n",
    "- how many tasters are there?\n",
    "- how long are the descriptions?\n",
    "- what are the top 20 wineries by number of wines? how do their points compare?\n",
    "- what is the most produced variety?\n",
    "- what is hightest rated variety?\n",
    "- what are the most controversial wine varieties?\n",
    "- are some tasters pickier than others?\n",
    "- what are the top 10 best value wines?\n",
    "- given a taster, what are their favorite varieties?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20 = df.winery.value_counts(dropna=False)[:20].index\n",
    "top20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_sorted(df[df.winery.isin(top20)], by=\"winery\", column=\"points\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"winery\")[\"points\"].describe().sort_values(\"count\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year\"] = df.title.str.extract(\"(19|20\\d{2})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.taster_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.country\n",
    "   .value_counts(ascending=True, dropna=False)\n",
    "   .plot.barh(figsize=(10,12), logx=True));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = (df.loc[df.country != '', 'country']\n",
    "               .unique()\n",
    "               .tolist())\n",
    "\n",
    "countries_regex = '(' + '|'.join(countries) + ')'\n",
    "countries_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_countries = (df.loc[df.country == '', 'description']\n",
    "                     .str.extract(countries_regex)\n",
    "                     .dropna())\n",
    "found_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[found_countries.index, 'country'] = found_countries.values\n",
    "df.loc[found_countries.index, 'country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.description\n",
    "   .str.len()\n",
    "   .plot.hist(title='Description length')\n",
    "   .set(xlabel=\"Length\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.points.plot.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_sorted(df, by=\"taster_name\", column=\"points\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_favs(name, min_count=10):\n",
    "    favs = df[df.taster_name == name].groupby('variety')['points'].describe(percentiles=[.95]).sort_values('95%', ascending=False)\n",
    "    return favs[favs['count'] >= min_count]\n",
    "\n",
    "get_favs(\"Virginie Boone\").head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['variety'])['points'].var().dropna().sort_values(ascending=False).head(15).plot.barh();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.points.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_good'] = df.points > 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.pipeline import *\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.compose import *\n",
    "from sklearn.impute import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "from workshop import show_most_informative_features\n",
    "\n",
    "def evaluate(model, X, y):\n",
    "    predictions = model.predict(X)\n",
    "    score = metrics.accuracy_score(y, predictions)\n",
    "    print('\\nAccuracy: %0.3f' % score)\n",
    "\n",
    "    print(metrics.classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, train_labels, test_labels = train_test_split(\n",
    "    df.drop(columns=['is_good', 'price', 'points']), \n",
    "    df.is_good,\n",
    "    random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "count_model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "\n",
    "count_model.fit(train_df.description, train_labels)\n",
    "\n",
    "evaluate(count_model, test_df.description, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tf_idf_model = make_pipeline(\n",
    "            make_column_transformer(\n",
    "                (TfidfVectorizer(ngram_range=(1,3)), \"description\")),\n",
    "            SGDClassifier(n_jobs=-1, max_iter=1000))\n",
    "\n",
    "tf_idf_model.fit(train_df, train_labels)\n",
    "\n",
    "evaluate(tf_idf_model, test_df, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_most_informative_features(tf_idf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "categorical_features = ['country', 'winery']\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value='missing'),\n",
    "    OneHotEncoder(handle_unknown='ignore'))\n",
    "\n",
    "model = make_pipeline(\n",
    "            make_column_transformer(\n",
    "                (TfidfVectorizer(), \"description\"),\n",
    "                (categorical_transformer, categorical_features),\n",
    "                (make_pipeline(\n",
    "                    SimpleImputer(strategy='median'),\n",
    "                    StandardScaler()), [\"year\"])),\n",
    "            SGDClassifier(n_jobs=-1, max_iter=1000))\n",
    "\n",
    "model.fit(train_df, train_labels)\n",
    "\n",
    "predicted = model.predict(test_df)\n",
    "\n",
    "score = metrics.accuracy_score(test_labels, predicted)\n",
    "print('\\nAccuracy: %0.3f' % score)\n",
    "\n",
    "print(metrics.classification_report(test_labels, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_most_informative_features(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_failures(model, X, y, cv=3):\n",
    "    predicted = cross_val_predict(model, X, y, cv=cv, n_jobs=-1)\n",
    "\n",
    "    print(\"Confusion matrix (actual x prediction):\")\n",
    "    print(metrics.confusion_matrix(y, predicted))\n",
    "\n",
    "    fn = X[(y == True) & (predicted == False)]\n",
    "    fp = X[(y == False) & (predicted == True)]\n",
    "\n",
    "    return fn, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn, tp = get_failures(model, train_df, train_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('.venv')",
   "metadata": {
    "interpreter": {
     "hash": "b40721bd6e5824e9d249fdf157fd422fb049cf4e9b216c8429d1167f9e3d5c34"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}